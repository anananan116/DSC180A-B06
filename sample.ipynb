{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "Small models: llama 3.1 8b/\n",
    "\n",
    "\n",
    "Read one sample from math dataset (question -> final answer)\n",
    "\n",
    "prompt small model to solve the question step by step with derived final answer. prompt the model to give some kind of formatted output like this:\n",
    "\n",
    "\"\"\"\n",
    "step 1:\n",
    "...\n",
    "\n",
    "step 2:\n",
    "...\n",
    "\n",
    "step 3:\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "Final answer: ...\n",
    "\"\"\"\n",
    "\n",
    "Check if the answer is correct -> if correct, skip this sample\n",
    "\n",
    "\n",
    "Could fine-tune the model for structured output.\n",
    "\n",
    "-> if not go to step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition: Step 1 -> Step 2\n",
    "\n",
    "list of str [\"reasoning step 1\", \"reasoning step 2\", ..., \"final answer\"]\n",
    "\n",
    "I can provide a generation function for step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2:\n",
    "THE MODEL could be GPT 4o, GPT 4o mini, llama 3.1 70b\n",
    "\n",
    "\n",
    "Prompt \"THE MODEL\" to verify step by step, stop when it sees the first step that's wrong.\n",
    "\n",
    "Ask it to return a structured output of the format\n",
    "\n",
    "{\n",
    "    error_step: int\n",
    "    reason: str\n",
    "    how_to_fix: str\n",
    "}\n",
    "go to step 3\n",
    "\n",
    "implement a answer checker.\n",
    "recieve question, correct answer, answer\n",
    "send to 4o mini\n",
    "return if the answer match the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition: Step 2 -> Step 3\n",
    "dict:\n",
    "{\n",
    "    error_step: int\n",
    "    reason: str\n",
    "    how_to_fix: str\n",
    "}\n",
    "question\n",
    "previous answer\n",
    "correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3:\n",
    "prompt the smaller model to try again:\n",
    "\n",
    "here's the correct steps:\n",
    "step 1:\n",
    "...\n",
    "\n",
    "step 2:\n",
    "...\n",
    "\n",
    "step 3:\n",
    "but step 3 is wrong with the reason: ..., you could fix it by:...\n",
    "\n",
    "\n",
    "Reply by smaller model\n",
    "\"\"\"\n",
    "retry:\n",
    "\n",
    "step 3:\n",
    "\n",
    "step 4:\n",
    "\n",
    "...\n",
    "\n",
    "final answer:\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "-> verify final answer.(by exact match or by gpt 4o mini) If correct, save the chain, if not correct check the number of iterations, if it doesn't pass the max interation allowed, go back to step 2.\n",
    "\n",
    "if correct, return True, None\n",
    "if incorrect, return False, Reply by smaller model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
